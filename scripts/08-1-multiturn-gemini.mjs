// scripts/08-1-multiturn-gemini.mjs
import "dotenv/config";
import readline from "readline";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { HumanMessage, AIMessage } from "@langchain/core/messages";

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

function ask(q) {
  return new Promise((resolve) => rl.question(q, resolve));
}

function buildModel() {
  const llm = new ChatGoogleGenerativeAI({
    model: process.env.GEMINI_MODEL,
    apiKey: process.env.GEMINI_API_KEY,
    temperature: 0.7,
  });

  return llm;
}

async function main() {
  console.log("Gemini ë©€í‹°í„´ ì±—ë´‡ ì‹œì‘! (ì¢…ë£Œ: exit / quit)");

  const llm = buildModel();

  /** ğŸ”¥ ì—¬ê¸°ì„œê°€ â€˜ë©”ëª¨ë¦¬â€™ ì—­í• ì„ í•˜ëŠ” ë¶€ë¶„ */
  /** LangChain Memory ëŒ€ì‹  ê·¸ëƒ¥ ë©”ì‹œì§€ ë°°ì—´ë¡œ ê´€ë¦¬ */
  const history = [
    new HumanMessage("ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ë¹„ì„œì•¼."),
  ];

  while (true) {
    const input = await ask("\në‚˜: ");
    if (["exit", "quit"].includes(input.trim().toLowerCase())) {
      console.log("ì±—ë´‡ ì¢…ë£Œ");
      break;
    }

    // 1) ì‚¬ìš©ìì˜ ìƒˆ ë©”ì‹œì§€ë¥¼ historyì— ì¶”ê°€
    history.push(new HumanMessage(input));

    // 2) ì§€ê¸ˆê¹Œì§€ì˜ ì „ì²´ historyë¥¼ ëª¨ë¸ì— ë„£ì–´ì„œ í˜¸ì¶œ
    const res = await llm.invoke(history);

    // 3) ë‹µë³€ ì¶œë ¥
    console.log(`ë´‡: ${res.content}`);

    // 4) AIì˜ ì‘ë‹µë„ historyì— ì¶”ê°€
    history.push(res);
  }

  rl.close();
}

main();
